This project focuses on implementing a Transformer model from scratch for natural language processing (NLP) tasks. 
The objective is to train and evaluate the Transformer model on the Wiki-2-Text dataset, which consists of text documents from Wikipedia. 
The model will be trained to generate coherent and meaningful text based on the input data. Additionally, the project includes an example 
of transfer learning, where the trained Transformer model is applied to the PennTreeBank dataset for further evaluation and generating 
random predictions.

To request access to the Data folder, please send me an email, and I will be glad to provide you with a link that includes all the files.

requirements.txt: This file lists the required dependencies and their versions for running the project. 
It is recommended to set up a conda virtual environment and install the dependencies using ```conda install --file requirements.txt```
